{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b04e58-f46b-4a66-9d50-15b8a02c9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1109b3dc-b1a6-4efb-938a-d083d7a7733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample tweets (Replace with your actual dataset)\n",
    "tweets = [\n",
    "    \"@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/iFz9FAn2Pa and https://t.co/xX6ghGFzCC and https://t.co/I2NlzdxNo8 advice Talk to your neighbours family to exchange phone numbers create contact list with phone numbers of neighbours schools employer chemist GP set up online shopping accounts if poss adequate supplies of regular meds but not over order\",\n",
    "    \"Coronavirus Australia: Woolworths to give elderly, disabled dedicated shopping hours amid COVID-19 outbreak https://t.co/bInCA9Vp8P\",\n",
    "    \"\\\"My food stock is not the only one which is empty... PLEASE, don't panic, THERE WILL BE ENOUGH FOOD FOR EVERYONE if you do not take more than you need. Stay calm, stay safe. #COVID19france #COVID_19 #COVID19 #coronavirus #confinement #Confinementotal #ConfinementGeneral https://t.co/zrlG0Z520j\\\"\",\n",
    "    \"\\\"Me, ready to go at supermarket during the #COVID19 outbreak. Not because I'm paranoid, but because my food stock is litteraly empty. The #coronavirus is a serious thing, but please, don't panic. It causes shortage... #CoronavirusFrance #restezchezvous #StayAtHome #confinement https://t.co/usmuaLq72n\\\"\",\n",
    "    \"As news of the regionâ€™s first confirmed COVID-19 case came out of Sullivan County last week, people flocked to area stores to purchase cleaning supplies, hand sanitizer, food, toilet paper and other goods, @Tim_Dodson reports https://t.co/cfXch7a2lU\",\n",
    "    \"Cashier at grocery store was sharing his insights on #Covid_19 To prove his credibility he commented \\\"I'm in Civics class so I know what I'm talking about\\\". https://t.co/ieFDNeHgDO\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5876893-258c-4f07-b901-618b7c05ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Cleaning\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove mentions (@username) and hashtags (#hashtag)\n",
    "    text = re.sub(r'@\\S+|#\\S+', '', text)\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b61b6058-f3a3-4ae2-8327-5a98bbf0eb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tweets = [clean_text(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb75ad0-ccd2-41c4-ad70-0ffb52ed4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Tokenization\n",
    "def tokenize(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc50660a-4e8f-4093-a0a1-c0f99cc6d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [tokenize(tweet) for tweet in cleaned_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab3f757-2f2b-4126-89d3-e40a8b0c5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Term Frequency Calculation\n",
    "def calculate_tf(tokens):\n",
    "    token_count = Counter(tokens)\n",
    "    total_tokens = len(tokens)\n",
    "    tf = {term: count / total_tokens for term, count in token_count.items()}\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f73917-4161-4cc6-8b8d-177e1ed9b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_scores = [calculate_tf(doc) for doc in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07005728-f217-4025-8618-da667f0a69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: TF-IDF Calculation (Term Frequency - Inverse Document Frequency)\n",
    "def calculate_idf(documents, term):\n",
    "    doc_count = sum(1 for doc in documents if term in doc)\n",
    "    if doc_count > 0:\n",
    "        return log(len(documents) / doc_count)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373a7055-1cb5-4f1f-892f-06c7a8b387ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tfidf(documents, tf):\n",
    "    tfidf = {}\n",
    "    for term, tf_value in tf.items():\n",
    "        idf_value = calculate_idf(documents, term)\n",
    "        tfidf[term] = tf_value * idf_value\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9080948-c704-42d6-bc80-a3c1633e2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores = [calculate_tfidf(tokenized_text, tf) for tf in tf_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60178d9d-64cd-4de3-9ea6-0ada63417221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Vectorize the data (create a term-document matrix)\n",
    "all_terms = sorted(set(term for tf in tf_scores for term in tf.keys()))\n",
    "vectorized_data = []\n",
    "\n",
    "for tfidf in tfidf_scores:\n",
    "    row = [tfidf.get(term, 0) for term in all_terms]\n",
    "    vectorized_data.append(row)\n",
    "\n",
    "# Convert the vectorized data into a numpy array\n",
    "X = np.array(vectorized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddacdd54-9e32-458c-ae80-a6a8d10381cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: K-means Clustering\n",
    "def k_means(X, k, max_iters=100):\n",
    "    # Randomly initialize centroids by selecting random data points\n",
    "    centroids = X[np.random.choice(X.shape[0], k, replace=False)]\n",
    "    prev_centroids = centroids.copy()\n",
    "    clusters = np.zeros(X.shape[0])\n",
    "\n",
    "    for _ in range(max_iters):\n",
    "        # Step 1: Assign clusters based on the closest centroid\n",
    "        for i, point in enumerate(X):\n",
    "            distances = np.linalg.norm(point - centroids, axis=1)\n",
    "            clusters[i] = np.argmin(distances)\n",
    "        \n",
    "        # Step 2: Update centroids\n",
    "        for i in range(k):\n",
    "            cluster_points = X[clusters == i]\n",
    "            if len(cluster_points) > 0:\n",
    "                centroids[i] = np.mean(cluster_points, axis=0)\n",
    "        \n",
    "        # If centroids don't change, break early\n",
    "        if np.all(centroids == prev_centroids):\n",
    "            break\n",
    "        \n",
    "        prev_centroids = centroids.copy()\n",
    "    \n",
    "    return centroids, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87df4c21-d7b8-4326-a513-68b99f4e01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-means clustering\n",
    "k = 2  # Example: We choose 2 clusters\n",
    "centroids, clusters = k_means(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e91a882c-35fc-42be-94cd-f2b4fbb4fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet 1: Cluster 0\n",
      "Tweet 2: Cluster 0\n",
      "Tweet 3: Cluster 1\n",
      "Tweet 4: Cluster 0\n",
      "Tweet 5: Cluster 0\n",
      "Tweet 6: Cluster 0\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Display the clusters\n",
    "# Display cluster assignments for each tweet\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(f\"Tweet {i + 1}: Cluster {int(cluster)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
